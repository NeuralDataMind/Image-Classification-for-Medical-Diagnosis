{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVaoRqd6IOlTXKUp9szZZx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-0zTXukQXPv","executionInfo":{"status":"ok","timestamp":1740406869196,"user_tz":-330,"elapsed":213473,"user":{"displayName":"Mallikarjun Reddy Bardipuram","userId":"16605990334793334039"}},"outputId":"a02e0cda-7f33-41a8-b52d-dbb7c901aa24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0484 - val_accuracy: 1.0000 - val_loss: 8.1481e-22\n","Epoch 2/10\n","\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 5.3624e-13 - val_accuracy: 1.0000 - val_loss: 8.1481e-22\n","Epoch 3/10\n","\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 2.2198e-11 - val_accuracy: 1.0000 - val_loss: 8.1481e-22\n","Epoch 4/10\n","\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 7.0770e-13 - val_accuracy: 1.0000 - val_loss: 8.1481e-22\n","Epoch 5/10\n","\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 9.7714e-11 - val_accuracy: 1.0000 - val_loss: 8.1461e-22\n","Epoch 6/10\n","\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 6.9901e-13 - val_accuracy: 1.0000 - val_loss: 8.1460e-22\n","Epoch 7/10\n","\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 1.5888e-13 - val_accuracy: 1.0000 - val_loss: 8.1460e-22\n","Epoch 8/10\n","\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 3.5643e-10 - val_accuracy: 1.0000 - val_loss: 8.1363e-22\n","Epoch 9/10\n","\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 4.3138e-10 - val_accuracy: 1.0000 - val_loss: 8.1287e-22\n","Epoch 10/10\n","\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 7.4170e-12 - val_accuracy: 1.0000 - val_loss: 8.1287e-22\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["import cv2\n","import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from PIL import Image\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","from keras.utils import normalize\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras.utils import to_categorical\n","\n","\n","image_directory = '/content/dataset'\n","\n","no_tumor_images = os.listdir(image_directory + '/no/') # Added '/' here\n","yes_tumor_images = os.listdir(image_directory + '/yes/') # Added '/' here\n","dataset = []\n","label = []\n","\n","INPUT_SIZE = 64\n","\n","# print(yes_tumor_images)\n","\n","# path = 'no0.jpg'\n","\n","# print(path.split('.')[1])\n","\n","for i , image_name in enumerate(no_tumor_images):\n","    if(image_name.split('.')[1] == 'jpg'):\n","        image = cv2.imread(image_directory + '/no/' + image_name) #Added '/' here\n","        image = Image.fromarray(image, 'RGB')\n","        image = image.resize((INPUT_SIZE, INPUT_SIZE))\n","        dataset.append(np.array(image))\n","        label.append(1)\n","\n","for i , image_name in enumerate(yes_tumor_images):\n","    if(image_name.split('.')[1] == 'jpg'):\n","        image = cv2.imread(image_directory + '/yes/' + image_name) # Added '/' here\n","        image = Image.fromarray(image, 'RGB')\n","        image = image.resize((INPUT_SIZE, INPUT_SIZE))\n","        dataset.append(np.array(image))\n","        label.append(1)\n","\n","dataset = np.array(dataset)\n","label = np.array(label)\n","\n","x_train, x_test, y_train, y_test = train_test_split(dataset, label, test_size=0.2, random_state=0)\n","\n","# Reshape = (n, image_width, image_height, n_channel)\n","\n","# print(x_train.shape)\n","# print(y_train.shape)\n","\n","# print(x_test.shape)\n","# print(y_test.shape)\n","\n","x_train = normalize(x_train, axis=1)\n","x_test = normalize(x_test, axis=1)\n","\n","\n","y_train = to_categorical(y_train, num_classes=2)\n","y_test = to_categorical(y_test, num_classes=2)\n","\n","# Model Bulding\n","# 64,6,3\n","\n","\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(INPUT_SIZE, INPUT_SIZE, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(32, (3, 3), kernel_initializer='he_uniform')) # Corrected spelling of 'kernal_initializer' to 'kernel_initializer'\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","model.add(Conv2D(32, (3, 3), kernel_initializer='he_uniform')) # Corrected spelling of 'kernal_initializer' to 'kernel_initializer'\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(2))\n","model.add(Activation('softmax'))\n","\n","# Binary CrossEntropy = 1, sigmoid\n","# Categorical Cross CrossEntropy = 2, softmax\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # Corrected spelling of compile\n","\n","model.fit(x_train, y_train, batch_size=16, verbose=1, epochs=10, validation_data=(x_test, y_test), shuffle=False)\n","\n","model.save('BrainTumor10Epochs.h5')"]}]}